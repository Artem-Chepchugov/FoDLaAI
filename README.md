# ДОМАШНЯЯ РАБОТА №2

## Задание 1: Модификация существующих моделей  
**Файл:** `homework_model_modification.py`

---

### 1.1 Расширение линейной регрессии

Модифицирована модель линейной регрессии (`LinearRegressionModel`):

- Добавлена L1/L2 регуляризация
- Реализован early stopping
- Используется nn.MSELoss и оптимизатор SGD 
- Вывод логов через logging 
- Обучение тестируется функцией test_linear_model()

---

### 1.2 Расширение логистической регрессии

Модифицирована модель логистической регрессии (`LogisticRegressionModel`):

- Добавлена поддержка многоклассовой классификации
- Реализованы метрики: precision, recall, F1-score, ROC-AUC (ovr)  
- Визуализация confusion matrix (seaborn.heatmap)  
- Отчёт по метрикам — classification_report
- Сохраняется график: plots/confusion_matrix.png 
- Происходит проверка: test_logistic_model()

---

## Задание 2: Работа с датасетами 
**Файл:** `homework_datasets.py`

---

### 2.1 Кастомный Dataset класс

- Реализован класс `CSVDataset` для загрузки данных из CSV-файла  
- Автоматическая предобработка:  
  - Нормализация числовых признаков (`StandardScaler`)  
  - Кодирование категориальных и бинарных признаков (`OneHotEncoder`)  
- Поддержка различных форматов данных: числовые, категориальные, булевы  
- Поддержка задач регрессии и классификации (с `LabelEncoder` для целевой переменной)  
- Обработка пропусков (удаление строк с NaN)  
- Гибкие параметры:  
  - Путь к файлу, разделитель CSV, список столбцов для удаления

---

### 2.2 Эксперименты с различными датасетами

- Линейная регрессия (`LinearRegressionModel`) и логистическая регрессия (`LogisticRegressionModel`) реализованы 
- Модульное обучение с функциями `train_model()` и `evaluate_model()`  
- Используются подходящие функции потерь: `MSELoss` для регрессии, `CrossEntropyLoss` для классификации  
- Метрики:  
  - Регрессия: MSE, R2  
  - Классификация: precision, recall, F1-score, confusion matrix с визуализацией  
- Эксперименты с двумя реальными датасетами:  
  - Titanic (бинарная классификация, предсказание выживания)  
  - Wine Quality (регрессия, предсказание качества вина)  
- Логирование процесса обучения с помощью `logging`  
- Сохранение графиков (confusion matrix) в папку `plots/`

---

## Задание 3: Эксперименты и анализ  
**Файл:** `homework_experiments.py`

---

### 3.1 Исследование гиперпараметров

Проведено систематическое тестирование модели линейной регрессии на датасете Wine Quality с использованием различных комбинаций гиперпараметров:

- Learning Rate: `0.001`, `0.01`, `0.1`
- Batch Size: `16`, `32`, `64`
- Оптимизаторы: `SGD`, `Adam`, `RMSprop`

Для каждой конфигурации рассчитывается метрика R², отображающая качество модели.  
Результаты выводятся в консоль в виде таблицы и сохраняются на графике:

- График: plots/hyperparam_comparison.png
- Ось X — название конфигурации
- Ось Y — значение R²

---

### 3.2 Feature Engineering

Реализовано расширение признаков для улучшения качества модели. Используются:

- Полиномиальные признаки: генерация квадратов и перекрёстных произведений
- Взаимодействия между признаками: перемножение выбранных пар признаков
- Статистические признаки: среднее и дисперсия по ряду признаков

Процесс:

- Исходные признаки обрабатываются с помощью `PolynomialFeatures` и ручного расчёта взаимодействий
- Добавляются два новых признака: `feature_mean`, `feature_std`
- Данные нормализуются перед обучением

Сравнение:

- Производится обучение модели на базовом и расширенном датасете
- Выводятся значения метрик R² для каждого случая
- Строится график сравнения: plots/feature_engineering_comparison.png

---
