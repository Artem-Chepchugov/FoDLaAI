# ДОМАШНЯЯ РАБОТА №1

## Задание 1: Создание и манипуляции с тензорами

**Файл:** `homework_tensors.py`

### 1.1 Создание тензоров

Созданы и выведены в консоль следующие тензоры с помощью библиотеки `torch`:

- `3x4` — случайные числа от 0 до 1 (`torch.rand`)
- `2x3x4` — заполненный нулями (`torch.zeros`)
- `5x5` — заполненный единицами (`torch.ones`)
- `4x4` — числа от 0 до 15, преобразованные из одномерного тензора через `reshape`

---

### 1.2 Операции с тензорами

Используются тензоры:

- `A` — размер `3x4`, создан при помощи `torch.arange(12).reshape(3, 4)`
- `B` — размер `4x3`, создан при помощи `torch.arange(12).reshape(4, 3)`

Выполнены следующие действия:

- **Транспонирование A**: `torch.transpose(A, 0, 1)`
- **Матричное умножение**: `torch.matmul(A, B)`
- **Поэлементное умножение**: `A * B.T`
- **Сумма всех элементов в A**: `torch.sum(A)`

Все результаты и промежуточные данные для визуальной проверки на корректность выполнения выведены на экран.

---

### 1.3 Индексация и срезы

Создан тензор размером `5x5x5` при помощи `torch.arange(125).reshape(5, 5, 5)`

Выполнены срезы:

- **Первая строка (в данном случае первая строка первой матрицы)**: `tensor[:1, :1, :]`
- **Последний столбец (в данном случае последний столбец последней матрицы)**: `tensor[-1:, :, -1:]`
- **Центральная подматрица 2x2 (взята из середины третьей матрицы)**: `tensor[2, 1:3, 1:3]`
- **Четные индексы по последней оси**: `tensor[:, :, ::2]`

Каждый срез выведен в консоль и визуально проверен на соответствие требованиям.

---

### 1.4 Работа с формами

Создан одномерный тензор на 24 элемента при помощи `torch.arange(24)`

Выполнены преобразования формы (`reshape`) в:

- `(2, 12)`
- `(3, 8)`
- `(4, 6)`
- `(2, 3, 4)`
- `(2, 2, 2, 3)`

Все полученные тензоры выведены в консоль и визуально проверены на соответствие требованиям.

---


## Задание 2: Автоматическое дифференцирование

**Файл:** `homework_autograd.py`

### 2.1 Простые вычисления с градиентами

Созданы тензоры `x1`, `y1`, `z1` размером `2x2` с `requires_grad=True`.  
Вычислена функция `f(x,y,z) = x^2 + y^2 + z^2 + 2*x*y*z`.  
Найден градиент по каждой переменной с помощью `backward()`.  

**Аналитическая проверка градиентов:**  
Мы имеем следующие тензоры:

```python
x = [[0.5963, 0.6749],
     [0.1428, 0.9079]]

y = [[-0.6246, -0.2375],
     [ 0.2625,  0.2699]]

z = [[ 0.2005, -0.4701],
     [ 0.6038, -1.2706]]
```

Посчитаем частные производные по каждой переменной:

- ∂f/∂x_ij = 2·x_ij + 2·y_ij·z_ij
- ∂f/∂y_ij = 2·y_ij + 2·x_ij·z_ij
- ∂f/∂z_ij = 2·z_ij + 2·x_ij·y_ij

Посчитаем все градиенты вручную:

x_00 = 0.5963  
y_00 = -0.6246  
z_00 = 0.2005  
∂f/∂x_00 = 2·x_00 + 2·y_00·z_00 = 2·0.5963 + 2·(-0.6246)·(0.2005) ≈ 1.1926 - 0.2504 ≈ 0.9422 - `сходится с выводом`   
∂f/∂y_00 = 2·y_00 + 2·x_00·z_00 = 2·(-0.6246) + 2·0.5963·0.2005 ≈ -1.2492 + 0.2391 ≈ -1.0101 - `присутствует минимальное расхождение на 0.0002`   
∂f/∂z_00 = 2·z_00 + 2·x_00·y_00 = 2·0.2005 + 2·0.5963·(-0.6246) ≈ 0.4010 - 0.7448 ≈ -0.3438 - `сходится с выводом`   

x_01 = 0.6749  
y_01 = -0.2375  
z_01 = -0.4701  
∂f/∂x_01 = 2·x_01 + 2·y_01·z_01 = 2·0.6749 + 2·(-0.2375)·(-0.4701) ≈ 1.3498 + 0.2234 ≈ 1.5732 - `сходится с выводом`   
∂f/∂y_01 = 2·y_01 + 2·x_01·z_01 = 2·(-0.2375) + 2·0.6749·(-0.4701) ≈ -0.4750 - 0.6345 ≈ -1.1095 - `присутствует минимальное расхождение на 0.0001`   
∂f/∂z_01 = 2·z_01 + 2·x_01·y_01 = 2·(-0.4701) + 2·0.6749·(-0.2375) ≈ -0.9402 - 0.3206 ≈ -1.2608 - `сходится с выводом`   

x_10 = 0.1428  
y_10 = 0.2625  
z_10 = 0.6038  
∂f/∂x_10 = 2·x_10 + 2·y_10·z_10 = 2·0.1428 + 2·0.2625·0.6038 ≈ 0.2856 + 0.3170 ≈ 0.6026 - `сходится с выводом`   
∂f/∂y_10 = 2·y_10 + 2·x_10·z_10 = 2·0.2625 + 2·0.1428·0.6038 ≈ 0.5250 + 0.1724 ≈ 0.6974 - `сходится с выводом`   
∂f/∂z_10 = 2·z_10 + 2·x_10·y_10 = 2·0.6038 + 2·0.1428·0.2625 ≈ 1.2076 + 0.0750 ≈ 1.2826 - `присутствует минимальное расхождение на 0.0002`   

x_11 = 0.9079  
y_11 = 0.2699  
z_11 = -1.2706  
∂f/∂x_11 = 2·x_11 + 2·y_11·z_11 = 2·0.9079 + 2·0.2699·(-1.2706) ≈ 1.8158 - 0.6858 ≈ 1.1300 - `сходится с выводом`   
∂f/∂y_11 = 2·y_11 + 2·x_11·z_11 = 2·0.2699 + 2·0.9079·(-1.2706) ≈ 0.5398 - 2.3072 ≈ -1.7673 - `сходится с выводом`   
∂f/∂z_11 = 2·z_11 + 2·x_11·y_11 = 2·(-1.2706) + 2·0.9079·0.2699 ≈ -2.5412 + 0.4900 ≈ -2.0512 - `присутствует минимальное расхождение на 0.0001`

В результате аналитической проверки вывод программы полностью подтвердился (за исключением небольших погрешностей, объяснимых приблизительными вычислениями с округлением до 4 знаков после запятой).

---

### 2.2 Градиент функции потерь

Реализована **функция среднеквадратичной ошибки MSE** = (1/n) * Σ(y_pred - y_true)², где y_pred = w·x + b


Переменные:

- `x2` и `y2_true` — вход и правильные значения (`2x2`)
- `w2` и `b2` — обучаемые параметры (`requires_grad=True`)

Вычислены:

- предсказание `y2_pred`
- функция потерь `mse`
- градиенты по `w2` и `b2` через `mse.backward()`

Градиенты корректно отражают направление минимизации MSE.

---

### 2.3 Цепное правило

Реализована **составная функция** f(x) = sin(x² + 1)


Градиент вычислен двумя способами:

1. Через `f3.sum().backward(retain_graph=True)`
2. Через `torch.autograd.grad(f3.sum(), x3)`

Обе версии возвращают совпадающие значения градиента по `x3`.

---

## Задание 3: Сравнение производительности CPU vs CUDA

**Файл:** `homework_performance.py`

### 3.1 Подготовка данных

Созданы три тензора со случайными значениями:
- `64 × 1024 × 1024`
- `128 × 512 × 512`
- `256 × 256 × 256`

Все тензоры были сгенерированы с использованием `torch.rand()`, они сохраняются на устройстве (CPU/GPU) в зависимости от доступности.

---

### 3.2 Измерение времени

Для точного измерения времени выполнения операций использовались:

- **На CPU**: `time.time()`
- **На GPU**: `torch.cuda.Event(start, end)` с `torch.cuda.synchronize()`

Операции сравнивались отдельно на CPU и CUDA (если доступна).

---

### 3.3 Результаты сравнения

#### Размер тензора: 64×1024×1024

| Операция               | CPU (мс) | GPU (мс) | Ускорение |
|------------------------|----------|----------|-----------|
| Матричное умножение    | 130.38   | 125.43   | ×1.04     |
| Поэлементное сложение  | 21.43    | 15.86    | ×1.35     |
| Поэлементное умножение | 10.49    | 10.04    | ×1.04     |
| Транспонирование       | 0.02     | 0.03     | ×0.58     |
| Суммирование           | 3.79     | 12.98    | ×0.29     |

#### Размер тензора: 128×512×512

| Операция               | CPU (мс) | GPU (мс) | Ускорение |
|------------------------|----------|----------|-----------|
| Матричное умножение    | 47.77    | 1.72     | ×27.74    |
| Поэлементное сложение  | 4.85     | 0.69     | ×7.00     |
| Поэлементное умножение | 4.20     | 0.69     | ×6.05     |
| Транспонирование       | 0.02     | 0.03     | ×0.64     |
| Суммирование           | 1.84     | 0.45     | ×4.07     |

#### Размер тензора: 256×256×256

| Операция               | CPU (мс) | GPU (мс) | Ускорение |
|------------------------|----------|----------|-----------|
| Матричное умножение    | 9.61     | 0.60     | ×16.05    |
| Поэлементное сложение  | 1.93     | 0.45     | ×4.30     |
| Поэлементное умножение | 1.84     | 0.39     | ×4.72     |
| Транспонирование       | 0.02     | 0.02     | ×0.87     |
| Суммирование           | 0.91     | 0.30     | ×3.07     |

---

### 3.4 Анализ результатов

- **Максимальное ускорение** достигается при матричном умножении, особенно при размерах от `128×512×512` и ниже.
- **Поэлементные операции** также выигрывают от использования CUDA, но в меньшей степени.
- **Транспонирование** выполняется очень быстро на CPU, поэтому в лучшем случае экономии от использования CUDA нет.
- **Суммирование** может быть медленнее на GPU на больших размерах из-за накладных расходов и редукций.
- **Вывод**: ускорение GPU зависит от типа операции и размера данных — чем больше и тяжелее вычисления, тем выше прирост.

#### Почему некоторые операции могут быть медленнее на GPU?

GPU показывает лучшую производительность только на достаточно больших и параллелизуемых задачах. Операции с малым объёмом данных (транспонирование или суммирование) не всегда оправдывают издержки на запуск ядра и могут выполняться быстрее на CPU.

#### Как размер матриц влияет на ускорение?

Чем больше матрица, тем больше параллелизма можно использовать на GPU. Это увеличивает загрузку вычислительных блоков и даёт реальный прирост производительности. На малых матрицах ускорение часто незаметно или вовсе отсутствует.

#### Что происходит при передаче данных между CPU и GPU?

Данные копируются между оперативной памятью (CPU) и видеопамятью (GPU). Эта операция медленная и может лишить преимущества от использования GPU, если делать её часто или с большими объёмами данных.

---